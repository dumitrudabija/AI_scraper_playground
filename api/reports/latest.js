// Import the scraping functions from the optimized scraper
async function scrapeAINews() {
  console.log('Scraping AI news sources...');
  
  const sources = [
    {
      name: 'TechCrunch AI',
      url: 'https://techcrunch.com/category/artificial-intelligence/feed/',
      color: '#00D100',
      category: 'business'
    },
    {
      name: 'VentureBeat AI',
      url: 'https://venturebeat.com/ai/feed/',
      color: '#1E88E5',
      category: 'business'
    },
    {
      name: 'MIT Technology Review',
      url: 'https://www.technologyreview.com/feed/',
      color: '#FF6B6B',
      category: 'development'
    },
    {
      name: 'AI News',
      url: 'https://artificialintelligence-news.com/feed/',
      color: '#4ECDC4',
      category: 'business'
    },
    {
      name: 'The Verge AI',
      url: 'https://www.theverge.com/ai-artificial-intelligence/rss/index.xml',
      color: '#FA7268',
      category: 'business'
    }
  ];

  const articles = [];
  
  for (const source of sources) {
    try {
      console.log(`Scraping ${source.name}...`);
      const sourceArticles = await scrapeRSSFeed(source);
      articles.push(...sourceArticles);
      console.log(`Found ${sourceArticles.length} articles from ${source.name}`);
    } catch (error) {
      console.error(`Error scraping ${source.name}:`, error.message);
    }
  }

  if (articles.length === 0) {
    console.log('No articles scraped, generating sample data...');
    return generateSampleArticles();
  }

  articles.sort((a, b) => new Date(b.pub_date) - new Date(a.pub_date));
  return articles.slice(0, 20);
}

async function scrapeRSSFeed(source) {
  try {
    const response = await fetch(source.url, {
      headers: {
        'User-Agent': 'Mozilla/5.0 (compatible; AI-News-Scraper/1.0)'
      },
      timeout: 10000
    });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }

    const xmlText = await response.text();
    const articles = parseRSSFeed(xmlText, source);
    return articles;
    
  } catch (error) {
    console.error(`Failed to scrape ${source.name}:`, error.message);
    return [];
  }
}

function parseRSSFeed(xmlText, source) {
  const articles = [];
  
  try {
    const itemRegex = /<item[^>]*>([\s\S]*?)<\/item>/gi;
    const items = xmlText.match(itemRegex) || [];
    
    for (const item of items.slice(0, 5)) {
      const title = extractXMLTag(item, 'title');
      const link = extractXMLTag(item, 'link');
      const description = extractXMLTag(item, 'description');
      const pubDate = extractXMLTag(item, 'pubDate');
      
      if (title && link) {
        articles.push({
          source: source.name,
          source_color: source.color,
          title: cleanText(title),
          link: link.trim(),
          description: cleanText(description).substring(0, 200),
          pub_date: parsePubDate(pubDate),
          category: source.category
        });
      }
    }
  } catch (error) {
    console.error(`Error parsing RSS for ${source.name}:`, error.message);
  }
  
  return articles;
}

function extractXMLTag(xml, tagName) {
  const regex = new RegExp(`<${tagName}[^>]*>([\\s\\S]*?)<\\/${tagName}>`, 'i');
  const match = xml.match(regex);
  return match ? match[1] : '';
}

function cleanText(text) {
  if (!text) return '';
  
  return text
    .replace(/<[^>]*>/g, '')
    .replace(/&lt;/g, '<')
    .replace(/&gt;/g, '>')
    .replace(/&amp;/g, '&')
    .replace(/&quot;/g, '"')
    .replace(/&#39;/g, "'")
    .replace(/&#8217;/g, "'")
    .replace(/&#8216;/g, "'")
    .replace(/&#8220;/g, '"')
    .replace(/&#8221;/g, '"')
    .replace(/&#8211;/g, 'â€“')
    .replace(/&#8212;/g, 'â€”')
    .replace(/&#8230;/g, 'â€¦')
    .replace(/&#(\d+);/g, (match, dec) => String.fromCharCode(dec))
    .replace(/\s+/g, ' ')
    .trim();
}

function parsePubDate(dateStr) {
  if (!dateStr) return new Date().toISOString();
  
  try {
    const date = new Date(dateStr);
    return date.toISOString();
  } catch (error) {
    return new Date().toISOString();
  }
}

function generateSampleArticles() {
  const now = new Date();
  const sources = [
    { name: 'TechCrunch AI', color: '#00D100', category: 'business' },
    { name: 'VentureBeat AI', color: '#1E88E5', category: 'business' },
    { name: 'MIT Technology Review', color: '#FF6B6B', category: 'development' },
    { name: 'AI News', color: '#4ECDC4', category: 'business' },
    { name: 'The Verge AI', color: '#FA7268', category: 'business' }
  ];

  const sampleTitles = [
    'New AI Model Achieves Breakthrough in Natural Language Understanding',
    'Machine Learning Advances in Computer Vision Applications',
    'AI Safety Research: Latest Developments and Challenges',
    'Large Language Models: Performance and Efficiency Improvements',
    'AI in Healthcare: Revolutionary Applications and Case Studies',
    'Robotics and AI Integration: Future Possibilities',
    'Neural Network Architecture Innovations',
    'AI Ethics and Responsible Development Practices',
    'Automated Code Generation: Tools and Techniques',
    'AI-Powered Data Analysis: New Methodologies'
  ];

  return sampleTitles.map((title, index) => {
    const source = sources[index % sources.length];
    const hoursAgo = Math.floor(Math.random() * 48) + 1;
    const pubDate = new Date(now.getTime() - hoursAgo * 60 * 60 * 1000);
    
    return {
      source: source.name,
      source_color: source.color,
      title: title,
      link: `https://example.com/article-${index + 1}`,
      description: `Latest developments in AI technology and research. This article covers recent advances and their implications for the future of artificial intelligence.`,
      pub_date: pubDate.toISOString(),
      category: source.category
    };
  });
}

export default async function handler(req, res) {
  // Set CORS headers
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  // Handle preflight requests
  if (req.method === 'OPTIONS') {
    res.status(200).end();
    return;
  }

  if (req.method !== 'GET') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    console.log('ðŸ”„ Generating fresh AI news report...');
    
    // Generate fresh data directly (no file system dependency)
    const articles = await scrapeAINews();
    
    // Calculate source statistics
    const sourceStats = {};
    for (const article of articles) {
      const source = article.source;
      const color = article.source_color;
      if (!sourceStats[source]) {
        sourceStats[source] = { name: source, count: 0, color: color };
      }
      sourceStats[source].count++;
    }

    const reportData = {
      report_date: new Date().toISOString().split('T')[0],
      generated_at: new Date().toISOString(),
      total_articles: articles.length,
      sources_count: new Set(articles.map(a => a.source)).size,
      articles: articles,
      sources: Object.values(sourceStats)
    };
    
    console.log(`âœ… Generated report with ${articles.length} articles from ${reportData.sources_count} sources`);
    
    res.json({
      success: true,
      data: reportData
    });
    
  } catch (error) {
    console.error('Error generating fresh report:', error);
    res.status(500).json({ 
      error: 'Failed to generate fresh report',
      message: error.message 
    });
  }
}
